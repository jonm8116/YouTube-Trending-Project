{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "11892\n",
      "Epoch 1/10\n",
      "11892/11892 [==============================] - 4s 300us/step - loss: 1.0112 - acc: 0.7950\n",
      "Epoch 2/10\n",
      "11892/11892 [==============================] - 2s 160us/step - loss: 0.4121 - acc: 0.8380\n",
      "Epoch 3/10\n",
      "11892/11892 [==============================] - 2s 155us/step - loss: 0.3855 - acc: 0.8565\n",
      "Epoch 4/10\n",
      "11892/11892 [==============================] - 2s 155us/step - loss: 0.3814 - acc: 0.8549\n",
      "Epoch 5/10\n",
      "11892/11892 [==============================] - 2s 147us/step - loss: 0.3724 - acc: 0.8624\n",
      "Epoch 6/10\n",
      "11892/11892 [==============================] - 2s 138us/step - loss: 0.3678 - acc: 0.8619\n",
      "Epoch 7/10\n",
      "11892/11892 [==============================] - 2s 141us/step - loss: 0.3628 - acc: 0.8620\n",
      "Epoch 8/10\n",
      "11892/11892 [==============================] - 2s 144us/step - loss: 0.3566 - acc: 0.8665\n",
      "Epoch 9/10\n",
      "11892/11892 [==============================] - 2s 139us/step - loss: 0.3574 - acc: 0.8682\n",
      "Epoch 10/10\n",
      "11892/11892 [==============================] - 2s 150us/step - loss: 0.3541 - acc: 0.8664\n",
      "12000\n",
      "11881\n",
      "Epoch 1/10\n",
      "11881/11881 [==============================] - 2s 151us/step - loss: 0.3566 - acc: 0.8644\n",
      "Epoch 2/10\n",
      "11881/11881 [==============================] - 2s 158us/step - loss: 0.3530 - acc: 0.8658\n",
      "Epoch 3/10\n",
      "11881/11881 [==============================] - 2s 161us/step - loss: 0.3519 - acc: 0.8670\n",
      "Epoch 4/10\n",
      "11881/11881 [==============================] - 2s 142us/step - loss: 0.3474 - acc: 0.8717\n",
      "Epoch 5/10\n",
      "11881/11881 [==============================] - 2s 139us/step - loss: 0.3434 - acc: 0.8741\n",
      "Epoch 6/10\n",
      "11881/11881 [==============================] - 2s 143us/step - loss: 0.3442 - acc: 0.8739\n",
      "Epoch 7/10\n",
      "11881/11881 [==============================] - 2s 141us/step - loss: 0.3485 - acc: 0.8636 \n",
      "Epoch 8/10\n",
      "11881/11881 [==============================] - 2s 149us/step - loss: 0.3430 - acc: 0.8704\n",
      "Epoch 9/10\n",
      "11881/11881 [==============================] - 2s 133us/step - loss: 0.3388 - acc: 0.8745\n",
      "Epoch 10/10\n",
      "11881/11881 [==============================] - 2s 127us/step - loss: 0.3395 - acc: 0.8716\n",
      "12000\n",
      "11869\n",
      "Epoch 1/10\n",
      "11869/11869 [==============================] - 2s 153us/step - loss: 0.3368 - acc: 0.8748\n",
      "Epoch 2/10\n",
      "11869/11869 [==============================] - 2s 134us/step - loss: 0.3345 - acc: 0.8774\n",
      "Epoch 3/10\n",
      "11869/11869 [==============================] - 2s 134us/step - loss: 0.3338 - acc: 0.8787\n",
      "Epoch 4/10\n",
      "11869/11869 [==============================] - 2s 151us/step - loss: 0.3353 - acc: 0.8729\n",
      "Epoch 5/10\n",
      "11869/11869 [==============================] - 2s 134us/step - loss: 0.3355 - acc: 0.8745\n",
      "Epoch 6/10\n",
      "11869/11869 [==============================] - 2s 129us/step - loss: 0.3292 - acc: 0.8814\n",
      "Epoch 7/10\n",
      "11869/11869 [==============================] - 2s 130us/step - loss: 0.3366 - acc: 0.8745\n",
      "Epoch 8/10\n",
      "11869/11869 [==============================] - 2s 133us/step - loss: 0.3317 - acc: 0.8758\n",
      "Epoch 9/10\n",
      "11869/11869 [==============================] - 2s 130us/step - loss: 0.3292 - acc: 0.8793\n",
      "Epoch 10/10\n",
      "11869/11869 [==============================] - 2s 131us/step - loss: 0.3279 - acc: 0.8801\n",
      "12000\n",
      "11875\n",
      "Epoch 1/10\n",
      "11875/11875 [==============================] - 2s 131us/step - loss: 0.3249 - acc: 0.8821\n",
      "Epoch 2/10\n",
      "11875/11875 [==============================] - 2s 130us/step - loss: 0.3310 - acc: 0.8751 1s -\n",
      "Epoch 3/10\n",
      "11875/11875 [==============================] - 2s 132us/step - loss: 0.3245 - acc: 0.8798\n",
      "Epoch 4/10\n",
      "11875/11875 [==============================] - 2s 171us/step - loss: 0.3284 - acc: 0.8745\n",
      "Epoch 5/10\n",
      "11875/11875 [==============================] - 2s 135us/step - loss: 0.3220 - acc: 0.8790\n",
      "Epoch 6/10\n",
      "11875/11875 [==============================] - 1s 126us/step - loss: 0.3260 - acc: 0.8781\n",
      "Epoch 7/10\n",
      "11875/11875 [==============================] - 2s 127us/step - loss: 0.3222 - acc: 0.8818\n",
      "Epoch 8/10\n",
      "11875/11875 [==============================] - 2s 135us/step - loss: 0.3239 - acc: 0.8776\n",
      "Epoch 9/10\n",
      "11875/11875 [==============================] - 2s 137us/step - loss: 0.3219 - acc: 0.8760\n",
      "Epoch 10/10\n",
      "11875/11875 [==============================] - 2s 135us/step - loss: 0.3248 - acc: 0.8777\n",
      "12000\n",
      "11890\n",
      "Epoch 1/10\n",
      "11890/11890 [==============================] - 2s 154us/step - loss: 0.3174 - acc: 0.8786\n",
      "Epoch 2/10\n",
      "11890/11890 [==============================] - 2s 158us/step - loss: 0.3173 - acc: 0.8797\n",
      "Epoch 3/10\n",
      "11890/11890 [==============================] - 2s 142us/step - loss: 0.3203 - acc: 0.8818\n",
      "Epoch 4/10\n",
      "11890/11890 [==============================] - 2s 158us/step - loss: 0.3170 - acc: 0.8796\n",
      "Epoch 5/10\n",
      "11890/11890 [==============================] - 2s 139us/step - loss: 0.3150 - acc: 0.8809\n",
      "Epoch 6/10\n",
      "11890/11890 [==============================] - 2s 130us/step - loss: 0.3160 - acc: 0.8784 1s\n",
      "Epoch 7/10\n",
      "11890/11890 [==============================] - 2s 146us/step - loss: 0.3134 - acc: 0.8839\n",
      "Epoch 8/10\n",
      "11890/11890 [==============================] - 2s 145us/step - loss: 0.3145 - acc: 0.8782\n",
      "Epoch 9/10\n",
      "11890/11890 [==============================] - 2s 136us/step - loss: 0.3119 - acc: 0.8835\n",
      "Epoch 10/10\n",
      "11890/11890 [==============================] - 2s 140us/step - loss: 0.3167 - acc: 0.8798\n",
      "800/800 [==============================] - 0s 190us/step\n",
      "test accuracy is 0.8025\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "Predict a video by entering a video id (or type 'quit' to exit): \n",
      "ccHhj_E245s\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0047efc20bc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predict a video by entering a video id (or type 'quit' to exit): \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[0mvideoId\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[0mvideo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetOneVideoStats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideoId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapiKey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'|S10'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;31m# print table of video data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ViewCount'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'LikeCount'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DislikeCount'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CommentCount'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Tags'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-0047efc20bc9>\u001b[0m in \u001b[0;36mgetOneVideoStats\u001b[1;34m(video_id, api_key)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetOneVideoStats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0msearchUrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"https://www.googleapis.com/youtube/v3/videos?id=\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"&key=\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"&part=statistics,snippet,content_details\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearchUrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 582\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "#Try model test\n",
    "\n",
    "#Read files for trending and non trending data set\n",
    "#import tensorflow to build neural network\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import re #import regex\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#For YouTube API Request\n",
    "import urllib\n",
    "import json\n",
    "from tabulate import tabulate\n",
    "#import regularizers to reduce overfitting\n",
    "\n",
    "def getApiKey(filename):\n",
    "    api_key_file = open(filename, 'r')\n",
    "    return api_key_file.read().rstrip()\n",
    "\n",
    "def standardizeTuple(t, d):\n",
    "    t -= np.mean(d, axis=0)\n",
    "    t /= np.std(d, axis=0)\n",
    "    return t\n",
    "\n",
    "def standardize(a):\n",
    "    d = np.array(a)\n",
    "    d -= np.mean(d, axis=0)\n",
    "    d /= np.std(d, axis=0)\n",
    "    return np.array(d)\n",
    "\n",
    "def getOneVideoStats(video_id, api_key):\n",
    "    searchUrl=\"https://www.googleapis.com/youtube/v3/videos?id=\"+video_id+\"&key=\"+api_key+\"&part=statistics,snippet,content_details\"\n",
    "    response = urllib.request.urlopen(searchUrl).read()\n",
    "    data = json.loads(response.decode('utf-8'))\n",
    "    try:\n",
    "        viewCount = data['items'][0]['statistics']['viewCount']\n",
    "        likeCount = data['items'][0]['statistics']['likeCount']\n",
    "        dislikeCount = data['items'][0]['statistics']['dislikeCount']\n",
    "        commentCount = data['items'][0]['statistics']['commentCount']\n",
    "        tagCount = len(data['items'][0]['snippet']['tags'])\n",
    "        categoryId = data['items'][0]['snippet']['categoryId']\n",
    "        return [[viewCount,likeCount,dislikeCount,commentCount, tagCount, categoryId]]\n",
    "    except (KeyError, IndexError):\n",
    "        return\n",
    "\n",
    "def getFullTrainingSet(trendDf, nontrendDf):\n",
    "    fullSubset = pd.concat([trendDf, nontrendDf])\n",
    "    #Drop duplicates between datasets\n",
    "    print(len(fullSubset))\n",
    "    fullSubset = fullSubset.drop_duplicates(subset='video_id', keep='first')\n",
    "    print(len(fullSubset))\n",
    "    trendingLabels = np.array(fullSubset['trending'].iloc[:])\n",
    "    fullSubset = fullSubset.drop(columns=['tags','trending','duration','video_id','video_title'], axis=1)\n",
    "    return (fullSubset, trendingLabels)\n",
    "\n",
    "def getNonTrendingSample(nontrendDf):\n",
    "    return nontrendDf.sample(n=6000)\n",
    "    \n",
    "def standardizeData(fullSubset):\n",
    "    #Standardize the data\n",
    "    matrixData = np.array(fullSubset)\n",
    "    matrixData = matrixData.astype('float32')\n",
    "    matrixData -= np.mean(matrixData, axis=0)\n",
    "    matrixData /= np.std(matrixData, axis=0)\n",
    "\n",
    "    # Add input scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaleMatrixData = scaler.fit_transform(matrixData)\n",
    "    return scaleMatrixData\n",
    "    \n",
    "trendingSet = pd.read_csv('../data/new-datasets/trending_dataset.csv')\n",
    "nontrendingSet = pd.read_csv('../data/new-datasets/nontrending_dataset.csv')\n",
    "trendingDf = pd.DataFrame(trendingSet)\n",
    "nontrendingDf = pd.DataFrame(nontrendingSet)\n",
    "\n",
    "subsetTrending = trendingDf.head(6000)\n",
    "subsetNontrending = nontrendingDf.head(len(subsetTrending))    \n",
    "\n",
    "#Test dataset\n",
    "trendingTestSet = trendingDf.iloc[-400:].drop(columns=['tags','trending','duration','video_id','video_title'], axis=1)\n",
    "nontrendingTestSet = nontrendingDf.iloc[-400:].drop(columns=['tags','trending','duration','video_id','video_title'], axis=1)\n",
    "totaldf = pd.concat([trendingTestSet, nontrendingTestSet])\n",
    "#convert to numpy array\n",
    "smallTestSet = np.array(totaldf)\n",
    "\n",
    "#test set labels\n",
    "trendingTestLabels = trendingDf.iloc[-400:]['trending']\n",
    "nontrendingTestLabels = nontrendingDf.iloc[-400:]['trending']\n",
    "totalTestlabels = np.concatenate([trendingTestLabels,nontrendingTestLabels])\n",
    "\n",
    "\n",
    "# Implement early stopping\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "\n",
    "# Build the feed forward Neural Network\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(300, kernel_regularizer=keras.regularizers.l2(0.01), activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(300, kernel_regularizer=keras.regularizers.l2(0.01)\n",
    "                             , activity_regularizer=keras.regularizers.l1(0.01), activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dropout(0.50))\n",
    "model.add(keras.layers.Dense(300, kernel_regularizer=keras.regularizers.l2(0.01)\n",
    "                             , activity_regularizer=keras.regularizers.l1(0.01), activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dropout(0.50))\n",
    "#Use softmax for activation function for output layer\n",
    "model.add(keras.layers.Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "#Compile model\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss='sparse_categorical_crossentropy', metrics=['accuracy'], callbacks=[early_stop]) #compile model\n",
    "\n",
    "#Train/fit model \n",
    "nonTrendingTrainSet = nontrendingDf.head(14000)\n",
    "all_data=[]\n",
    "for i in range(5):\n",
    "    nonTrendingDataSet = getNonTrendingSample(nonTrendingTrainSet)\n",
    "    setTuple = getFullTrainingSet(subsetTrending, nonTrendingDataSet)\n",
    "    fullSubset = setTuple[0]\n",
    "    all_data = setTuple[0]\n",
    "    trendingLabels = setTuple[1]\n",
    "    scaleMatrixData = standardizeData(fullSubset)\n",
    "    model.fit(scaleMatrixData, trendingLabels, epochs=10)\n",
    "\n",
    "#model test accuracy\n",
    "_, testacc = model.evaluate(smallTestSet, totalTestlabels)\n",
    "print(\"test accuracy is \" + str(testacc))\n",
    "\n",
    "#model predict \n",
    "predictions = model.predict(smallTestSet)\n",
    "print(predictions)\n",
    "\n",
    "#Drop trending column for prediction\n",
    "# print(all_data)\n",
    "\n",
    "#print current shape \n",
    "all_data = all_data.loc[:, ~all_data.columns.str.contains('^Unnamed')]\n",
    "# print(all_data)\n",
    "apiKey = getApiKey('apikey.txt')\n",
    "videoId = ''\n",
    "while (videoId != 'quit'):\n",
    "    print(\"Predict a video by entering a video id (or type 'quit' to exit): \")\n",
    "    videoId = input()\n",
    "    video = np.array(getOneVideoStats(videoId, apiKey), dtype='|S10').astype(float)\n",
    "    # print table of video data\n",
    "    print(\"\\n\" + tabulate(video, headers=['ViewCount', 'LikeCount', 'DislikeCount', 'CommentCount', 'Tags']))\n",
    "    all_data= np.array(all_data)\n",
    "    video = standardizeTuple(video, all_data)\n",
    "    video = video[0].T\n",
    "    print(fullSubset.shape)\n",
    "    print(video.shape)\n",
    "    # if video data was empty dont do a prediction\n",
    "    if (len(video) != 0):\n",
    "        prediction = model.predict(video)\n",
    "        # print table of prediction probabilities\n",
    "        print(\"\\n\" + tabulate(prediction, headers=['P(Non-Trending)', 'P(Trending)']))\n",
    "        # print prediction for video\n",
    "        if (np.argmax(prediction) == 1):\n",
    "            print(\"\\nPredicted Trending Video\\n\")\n",
    "        else:\n",
    "            print(\"\\nPredicted Non-Trending Video\\n\")\n",
    "    else:\n",
    "        print(\"Video missing views, likes, dislikes, or commentCount...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
