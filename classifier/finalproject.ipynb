{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.6 |Anaconda custom (64-bit)| (default, Aug 26 2018, 16:05:27) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 6)\n",
      "Epoch 1/50\n",
      "5800/5800 [==============================] - 2s 417us/step - loss: 0.5414 - acc: 0.7172 1s - loss: 0.5710\n",
      "Epoch 2/50\n",
      "5800/5800 [==============================] - 2s 296us/step - loss: 0.4661 - acc: 0.7816 0s - loss: 0.4684 - acc: 0.78\n",
      "Epoch 3/50\n",
      "5800/5800 [==============================] - 2s 343us/step - loss: 0.4220 - acc: 0.8028\n",
      "Epoch 4/50\n",
      "5800/5800 [==============================] - 2s 330us/step - loss: 0.4025 - acc: 0.8217\n",
      "Epoch 5/50\n",
      "5800/5800 [==============================] - 2s 287us/step - loss: 0.3733 - acc: 0.8410\n",
      "Epoch 6/50\n",
      "5800/5800 [==============================] - 2s 368us/step - loss: 0.3742 - acc: 0.8350\n",
      "Epoch 7/50\n",
      "5800/5800 [==============================] - 2s 389us/step - loss: 0.3633 - acc: 0.8414\n",
      "Epoch 8/50\n",
      "5800/5800 [==============================] - 2s 415us/step - loss: 0.3512 - acc: 0.8519 1s - loss: 0.\n",
      "Epoch 9/50\n",
      "5800/5800 [==============================] - 2s 314us/step - loss: 0.3502 - acc: 0.8547\n",
      "Epoch 10/50\n",
      "5800/5800 [==============================] - 2s 335us/step - loss: 0.3392 - acc: 0.8633\n",
      "Epoch 11/50\n",
      "5800/5800 [==============================] - 2s 311us/step - loss: 0.3409 - acc: 0.8616\n",
      "Epoch 12/50\n",
      "5800/5800 [==============================] - 2s 279us/step - loss: 0.3312 - acc: 0.8607\n",
      "Epoch 13/50\n",
      "5800/5800 [==============================] - 1s 258us/step - loss: 0.3319 - acc: 0.8550\n",
      "Epoch 14/50\n",
      "5800/5800 [==============================] - 1s 258us/step - loss: 0.3243 - acc: 0.8643\n",
      "Epoch 15/50\n",
      "5800/5800 [==============================] - 2s 261us/step - loss: 0.3260 - acc: 0.8691\n",
      "Epoch 16/50\n",
      "5800/5800 [==============================] - 1s 256us/step - loss: 0.3124 - acc: 0.8709\n",
      "Epoch 17/50\n",
      "5800/5800 [==============================] - 2s 260us/step - loss: 0.3175 - acc: 0.8674\n",
      "Epoch 18/50\n",
      "5800/5800 [==============================] - 2s 264us/step - loss: 0.3160 - acc: 0.8684\n",
      "Epoch 19/50\n",
      "5800/5800 [==============================] - 1s 254us/step - loss: 0.3128 - acc: 0.8740\n",
      "Epoch 20/50\n",
      "5800/5800 [==============================] - 2s 259us/step - loss: 0.3045 - acc: 0.8750\n",
      "Epoch 21/50\n",
      "5800/5800 [==============================] - 2s 259us/step - loss: 0.3002 - acc: 0.8766\n",
      "Epoch 22/50\n",
      "5800/5800 [==============================] - 2s 291us/step - loss: 0.3023 - acc: 0.8747\n",
      "Epoch 23/50\n",
      "5800/5800 [==============================] - 2s 262us/step - loss: 0.2920 - acc: 0.8800\n",
      "Epoch 24/50\n",
      "5800/5800 [==============================] - 2s 277us/step - loss: 0.2978 - acc: 0.8779\n",
      "Epoch 25/50\n",
      "5800/5800 [==============================] - 2s 262us/step - loss: 0.2953 - acc: 0.8779\n",
      "Epoch 26/50\n",
      "5800/5800 [==============================] - 2s 259us/step - loss: 0.2881 - acc: 0.8833\n",
      "Epoch 27/50\n",
      "5800/5800 [==============================] - 2s 280us/step - loss: 0.2887 - acc: 0.8829\n",
      "Epoch 28/50\n",
      "5800/5800 [==============================] - 2s 281us/step - loss: 0.2830 - acc: 0.8829\n",
      "Epoch 29/50\n",
      "5800/5800 [==============================] - 2s 280us/step - loss: 0.2840 - acc: 0.8824\n",
      "Epoch 30/50\n",
      "5800/5800 [==============================] - 2s 289us/step - loss: 0.2815 - acc: 0.8855\n",
      "Epoch 31/50\n",
      "5800/5800 [==============================] - 1s 253us/step - loss: 0.2846 - acc: 0.8847\n",
      "Epoch 32/50\n",
      "5800/5800 [==============================] - 2s 264us/step - loss: 0.2770 - acc: 0.8850\n",
      "Epoch 33/50\n",
      "5800/5800 [==============================] - 1s 256us/step - loss: 0.2726 - acc: 0.8878\n",
      "Epoch 34/50\n",
      "5800/5800 [==============================] - 2s 262us/step - loss: 0.2669 - acc: 0.8922\n",
      "Epoch 35/50\n",
      "5800/5800 [==============================] - 1s 256us/step - loss: 0.2639 - acc: 0.8955\n",
      "Epoch 36/50\n",
      "5800/5800 [==============================] - 1s 254us/step - loss: 0.2671 - acc: 0.8903\n",
      "Epoch 37/50\n",
      "5800/5800 [==============================] - 1s 256us/step - loss: 0.2691 - acc: 0.8897\n",
      "Epoch 38/50\n",
      "5800/5800 [==============================] - 2s 262us/step - loss: 0.2653 - acc: 0.8928\n",
      "Epoch 39/50\n",
      "5800/5800 [==============================] - 1s 257us/step - loss: 0.2645 - acc: 0.8912\n",
      "Epoch 40/50\n",
      "5800/5800 [==============================] - 1s 257us/step - loss: 0.2580 - acc: 0.8962\n",
      "Epoch 41/50\n",
      "5800/5800 [==============================] - 2s 263us/step - loss: 0.2577 - acc: 0.8952\n",
      "Epoch 42/50\n",
      "5800/5800 [==============================] - 2s 265us/step - loss: 0.2563 - acc: 0.8978\n",
      "Epoch 43/50\n",
      "5800/5800 [==============================] - 2s 303us/step - loss: 0.2572 - acc: 0.8921\n",
      "Epoch 44/50\n",
      "5800/5800 [==============================] - 2s 295us/step - loss: 0.2490 - acc: 0.9007\n",
      "Epoch 45/50\n",
      "5800/5800 [==============================] - 2s 279us/step - loss: 0.2561 - acc: 0.8953\n",
      "Epoch 46/50\n",
      "5800/5800 [==============================] - 2s 279us/step - loss: 0.2547 - acc: 0.8988\n",
      "Epoch 47/50\n",
      "5800/5800 [==============================] - 2s 259us/step - loss: 0.2425 - acc: 0.9033\n",
      "Epoch 48/50\n",
      "5800/5800 [==============================] - 2s 264us/step - loss: 0.2459 - acc: 0.9028\n",
      "Epoch 49/50\n",
      "5800/5800 [==============================] - 2s 261us/step - loss: 0.2445 - acc: 0.9028\n",
      "Epoch 50/50\n",
      "5800/5800 [==============================] - 1s 258us/step - loss: 0.2571 - acc: 0.8960\n",
      "5800/5800 [==============================] - 1s 98us/step\n",
      "\n",
      "\n",
      "Test Set Accuracy:0.845\n",
      "Predict a video by entering a video id (or type 'quit' to exit): \n",
      "8UrZ6P_4Tok\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, not 'bytes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-aab2742255d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-aab2742255d0>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predict a video by entering a video id (or type 'quit' to exit): \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mvideoId\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mvideo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetOneVideoStats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideoId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapiKey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'|S10'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[1;31m# print table of video data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ViewCount'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'LikeCount'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DislikeCount'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CommentCount'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CategoryId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Tags'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-aab2742255d0>\u001b[0m in \u001b[0;36mgetOneVideoStats\u001b[1;34m(video_id, api_key)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0msearchUrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"https://www.googleapis.com/youtube/v3/videos?id=\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"&key=\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"&part=statistics,snippet,content_details\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearchUrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mviewCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'items'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'statistics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'viewCount'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\John\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         raise TypeError('the JSON object must be str, not {!r}'.format(\n\u001b[1;32m--> 312\u001b[1;33m                             s.__class__.__name__))\n\u001b[0m\u001b[0;32m    313\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'\\ufeff'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         raise JSONDecodeError(\"Unexpected UTF-8 BOM (decode using utf-8-sig)\",\n",
      "\u001b[1;31mTypeError\u001b[0m: the JSON object must be str, not 'bytes'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "def getApiKey(filename):\n",
    "    api_key_file = open(filename, 'r')\n",
    "    return api_key_file.read().rstrip()\n",
    "\n",
    "def standardizeTuple(t, d):\n",
    "    t -= np.mean(d, axis=0)\n",
    "    t /= np.std(d, axis=0)\n",
    "    return t\n",
    "\n",
    "def standardize(a):\n",
    "    scaler = StandardScaler()\n",
    "    a = scaler.fit_transform(a)\n",
    "    d = np.array(a)\n",
    "    d = d.astype('float32')\n",
    "    d -= np.mean(d, axis=0)\n",
    "    d /= np.std(d, axis=0)\n",
    "    return np.array(d)\n",
    "\n",
    "def getOneVideoStats(video_id, api_key):\n",
    "    searchUrl=\"https://www.googleapis.com/youtube/v3/videos?id=\"+video_id+\"&key=\"+api_key+\"&part=statistics,snippet,content_details\"\n",
    "    response = urllib.request.urlopen(searchUrl).read()\n",
    "    data = json.loads(response.decode('utf-8'))\n",
    "    try:\n",
    "        viewCount = data['items'][0]['statistics']['viewCount']\n",
    "        likeCount = data['items'][0]['statistics']['likeCount']\n",
    "        dislikeCount = data['items'][0]['statistics']['dislikeCount']\n",
    "        commentCount = data['items'][0]['statistics']['commentCount']\n",
    "        categoryId = data['items'][0]['snippet']['categoryId']\n",
    "        tagLength = len(data['items'][0]['snippet']['tags'])\n",
    "        likeRatioCount = int(likeCount)/(int(likeCount)+int(dislikeCount))\n",
    "        commentRatioCount = int(commentCount)/int(viewCount)\n",
    "        return [[viewCount,likeCount,dislikeCount,commentCount, categoryId, tagLength]]\n",
    "    except (KeyError, IndexError):\n",
    "        return\n",
    "\n",
    "def main():\n",
    "    trendingSet = pd.read_csv('../data/new-datasets/trending_dataset.csv')\n",
    "    nontrendingSet = pd.read_csv('../data/new-datasets/nontrending_dataset.csv')\n",
    "    trendingSet = trendingSet[['views', 'likes', 'dislikes', 'comments', 'category_id', 'tags_length']]\n",
    "    nontrendingSet = nontrendingSet[['views', 'likes', 'dislikes', 'comments', 'category_id', 'tags_length']]\n",
    "    #trendingSet['likes_ratio'] = trendingSet['likes']/(trendingSet['likes']+trendingSet['dislikes'])\n",
    "    #trendingSet['comments_ratio'] = trendingSet['comments']/(trendingSet['views'])\n",
    "    \n",
    "    #nontrendingSet['likes_ratio'] = nontrendingSet['likes']/(nontrendingSet['likes']+nontrendingSet['dislikes'])\n",
    "    #nontrendingSet['comments_ratio'] = nontrendingSet['comments']/(nontrendingSet['views'])\n",
    "    \n",
    "    \n",
    "    #print(trendingSet)\n",
    "    trending_stats_non = trendingSet.values\n",
    "    nontrending_stats_non = nontrendingSet.values\n",
    "    #print(trending_stats_non.shape)\n",
    "    #print(nontrending_stats_non)\n",
    "    \n",
    "    #nontrending_stats_non = np.load('nontrending_stats.npy')\n",
    "    #trending_stats_non = np.load('trending_stats.npy')\n",
    "    # combine trending and nontrending data, then standardize them\n",
    "    all_data = np.concatenate((trending_stats_non[0:6000,:], nontrending_stats_non[0:6000]), axis=0)\n",
    "    \n",
    "    #all_data = all_data.astype('float32')\n",
    "    #print(all_data.shape)\n",
    "    standardized_data = standardize(all_data)\n",
    "    # sample tuple for a random video (views, likes, dislikes, commentCount)\n",
    "    exampleTuple = [[1713501,84894,2855,15155, 20, 12]]\n",
    "    print(all_data.shape)\n",
    "    exampleTuple = standardizeTuple(exampleTuple, all_data)\n",
    "    # split em up\n",
    "    trending_stats = standardized_data[0:6000,:]\n",
    "    nontrending_stats = standardized_data[6001:,:]\n",
    "    # curate sets of data necessary for neural net\n",
    "    train_data = np.concatenate((trending_stats[0:2900,:], nontrending_stats[0:2900,:]), axis = 0)\n",
    "    test_data = np.concatenate((trending_stats[2901:5801,:], nontrending_stats[2901:5801,:]), axis = 0)\n",
    "    train_labels = np.concatenate((np.ones(2900), np.zeros(2900)), axis = 0)\n",
    "    test_labels = np.concatenate((np.ones(2900), np.zeros(2900)), axis = 0)\n",
    "\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(512, input_dim=6,activation=tf.nn.relu),\n",
    "        keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "        (keras.layers.Dropout(0.50)),\n",
    "        keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "        (keras.layers.Dropout(0.50)),\n",
    "        keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "                    loss ='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    \n",
    "    #train_data = train_data.sample(frac=1)\n",
    "    model.fit(train_data, train_labels, epochs=50)\n",
    "    predictions = model.predict(test_data)\n",
    "    #print(predictions)\n",
    "    #print(test_labels.shape)\n",
    "    #truth = []\n",
    "    #print(test_labels)\n",
    "    #for i in range(len(predictions)):\n",
    "    #    if(predictions[i][0]==1):\n",
    "    #        truth.append(0)\n",
    "    #    else:\n",
    "    #        truth.append(1)\n",
    "    #print(predictions.shape)\n",
    "    #cm = tf.contrib.metrics.confusion_matrix(test_labels, truth)\n",
    "    #print(cm)\n",
    "    #return \n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "\n",
    "    print(\"\\n\\nTest Set Accuracy:\" + str(test_acc))\n",
    "\n",
    "    #history = model.fit(X, Y, validation_split=0.33, epochs=1000, batch_size=10, verbose=0, callbacks=[tb, early_stop])\n",
    "    # extra code so you can test individual video ids and see if trending or nontrending\n",
    "    apiKey = getApiKey('apikey.txt')\n",
    "    videoId = ''\n",
    "    while videoId != 'quit':\n",
    "        print(\"Predict a video by entering a video id (or type 'quit' to exit): \")\n",
    "        videoId = input()\n",
    "        video = np.array(getOneVideoStats(videoId, apiKey), dtype='|S10').astype(float)\n",
    "        # print table of video data\n",
    "        print(\"\\n\" + tabulate(video, headers=['ViewCount', 'LikeCount', 'DislikeCount', 'CommentCount', 'CategoryId', 'Tags']))\n",
    "        video = standardizeTuple(video, all_data)\n",
    "        # if video data was empty dont do a prediction\n",
    "        if (len(video) != 0):\n",
    "            print(video)\n",
    "            prediction = model.predict(video)\n",
    "            # print table of prediction probabilities\n",
    "            print(\"\\n\" + tabulate(prediction, headers=['P(Non-Trending)', 'P(Trending)']))\n",
    "            # print prediction for video\n",
    "            if (np.argmax(prediction) == 1):\n",
    "                print(\"\\nPredicted Trending Video\\n\")\n",
    "            else:\n",
    "                print(\"\\nPredicted Non-Trending Video\\n\")\n",
    "        else:\n",
    "            print(\"Video missing views, likes, dislikes, or commentCount...\")\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
